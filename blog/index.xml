<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on ServiceMesher</title>
    <link>https://servicemesher.github.io/blog/</link>
    <description>Recent content in Blogs on ServiceMesher</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Tue, 05 Jun 2018 19:12:42 +0800</lastBuildDate>
    
	<atom:link href="https://servicemesher.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>服务网格：8种方式简化微服务部署</title>
      <link>https://servicemesher.github.io/blog/8-ways-a-service-mesh-eases-microservices-deployment/</link>
      <pubDate>Tue, 05 Jun 2018 19:12:42 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/8-ways-a-service-mesh-eases-microservices-deployment/</guid>
      <description>原文地址：https://thenewstack.io/8-ways-a-service-mesh-eases-microservices-deployment/
作者：Robert Whiteley
译者：Grace
 基于微服务的架构是未来的趋势，但是实现这种架构会面临许多困难。现代应用架构远比过去的架构复杂，因此实现微服务架构将会带来了一系列特殊的挑战，而服务网格可以帮我们解决很多问题。
最近一段时间，管理者不再专注于调试单个应用程序服务器，相反，现代系统就像是一群牛，研究整体的行为远比单个的服务器更有意义，分布式系统就是一个典型。
微服务是一种分布式架构，目的在于通过不断调整自身以适应当前流量状况的变化，例如，有一组处理客户端请求路由的容器，改变这组容器，反过来也意味着路由表在不断变化，由此反映了应用程序端点的变化位置。与此同时，在任何架构体系中都会有过去的遗留物，从必须使用单个大型数据库服务器的应用程序到捆绑API以使其看起来是以服务为重点的遗留系统。
而服务网格是当前最先进的微服务模式。它建立在容器以及容器编排之上，配有处理内部服务通信的专用控制面。它负责协调分布式网格的微服务所需的安全性，路由，身份验证，授权和类似功能，服务网格将这些功能从应用程序（或应用程序的服务组件）中剥离出来作为可编程的基础组件。虽然不是所有的公司都需要如此复杂的服务网格（尽管这些公司大部分都运行着成百上千的服务），但服务网格正迅速成为那些希望运行生产级微服务的公司的默认架构。
以下是八种实现服务网格的方法，可以帮助您平滑过渡到微服务。
 改进微服务的消息处理机制。服务网格确保你能监控到整个架构层，不仅可以跟踪到网络中的服务器地址，还可以跟踪到传达服务器地址信息的消息。例如，你可能想要跟踪“失败”消息，但这些消息在传统云架构中通常会丢失。服务网格的好处是既可以确保消息的传递，又会在消息未到达目的地时返回错误信息。 利用与传统应用程序相同的运维方式。对于企业级网络来说，可定制性和灵活性是最重要的。服务网格是为适应现代分布式应用程序而设计的。但是底层的技术如入口控制器，负载均衡器，以及代理都和传统单体应用的数据层面的技术相同。在实现服务网格的过程中，组织可以利用到与运营现代、基于软件的应用程序交付基础设施相同的技术与技能。 灵活使用多种云服务。服务网格解决了现代应用的云网络问题。支撑起服务网格的数据平面和控制平面的技术独立于任何特定架构，因此它们可以在无论是裸机，容器还是虚拟机的公有或私有的架构上运行。这种灵活特性甚至允许服务网格处理未来的应用程序架构，从而发挥其规模化、全球复制以及深层性能调节等优势。您的服务网格将成为运作模式化云架构场景下，一切潜在优势的实现保障。 提高对微服务的可见性。分布式系统的指标对于我们而言就像是一个黑盒子，而网格服务为我们提供了一种更深入观察分布式系统的指标的途径。它会随时间收集性能指标，为团队提供服务可用性的长期指标。这为操作员提供了一种观察服务可靠性和性能的方式，使他们能够逐步优化系统。 更高效的运维以及更有效的执行SLA（服务等级协议）。服务网格提供的追踪功能对调试和故障排除至关重要，与此同时，它也确保服务执行了服务等级协议（SLA）。服务网格执行了很多任务，包括执行策略以及追踪查看这些策略是否被满足。它为管理者提供了一个可以在网络层实施云应用管理和策略的场所。 简化微服务实现。服务网格的另一大优点是可以轻松部署它们。过去的解决方案要求开发人员将服务内功能编码到每个微服务中。这需要重写应用程序并在不同的编程语言中维护各种库。而服务网格帮开发人员抽象了这些事务。开发人员可以简单地调用必要的消息传递和服务发现功能就可以轻松的部署它们，而微服务的源码只用包含业务逻辑相关的代码。 加快新服务的上线时间。过去的库解决方案，如Finagle、Hystrix和Stubby，需要开发人员长时间的介入并且迫使开发人员将冗余功能编码到每一个服务中。另一个更简单的方法是在每个微服务中放置一个sidecar代理并将它们连接在一起，这正是服务网格所擅长的，因此未来将会有更多的云应用选择服务网格架构。简而言之，服务网格保证了开发者的生产力，使他们能够更快地将更多的服务推向市场。 保障服务间的通信安全。服务之间通信有可能跨云，跨数据中心，或者跨大陆，而服务网格保障了这些通信的安全，它封装了所有的通信，并且在控制器层面协调这些通信，通过管道内加密，联系人策略和服务权限解决了安全问题。  转载自：https://mp.weixin.qq.com/s/Q-k0BtUz2U4bWiXXdeaw7g</description>
    </item>
    
    <item>
      <title>Istio 0.8 的 Helm Chart 解析</title>
      <link>https://servicemesher.github.io/blog/helm-chart-for-istio-0.8/</link>
      <pubDate>Mon, 04 Jun 2018 16:09:57 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/helm-chart-for-istio-0.8/</guid>
      <description>儿童节期间，拖拉了一个多月的 Istio 0.8 正式发布了，这可能是 Istio 1.0 之前的最后一个 LTS 版本，意义重大。
新版本中，原来的 Kubernetes 安装文件 install/kubernetes/istio.yaml，变成了 install/kubernetes/istio-demo.yaml，是的，你没看错，这个 LTS 的安装文件名字叫 demo。查看了一下文档，大概察觉到不靠谱的 Istio 发布组的意图了：这个项目的组件相对比较复杂，原有的一些选项是靠 ConfigMap 以及 istioctl 分别调整的，现在通过重新设计的 Helm Chart，安装选项用 values.yml 或者 helm 命令行的方式来进行集中管理了。下面就由看看 Istio 的 Helm Chart 的安装部署及其结构。
使用 Helm 安装 Istio 安装包内的 Helm 目录中包含了 Istio 的 Chart，官方提供了两种方法：
 用 Helm 生成 istio.yaml，然后自行安装。 用 Tiller 直接安装。  很明显，两种方法并没有什么本质区别。例如第一个命令：
helm template install/kubernetes/helm/istio \ --name istio --namespace \ istio-system &amp;gt; $HOME/istio.yaml  这里说的是使用 install/kubernetes/helm/istio 目录中的 Chart 进行渲染，生成的内容保存到 $HOME/istio.</description>
    </item>
    
    <item>
      <title>服务网格之路</title>
      <link>https://servicemesher.github.io/blog/the-path-to-service-mesh/</link>
      <pubDate>Mon, 04 Jun 2018 15:55:08 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/the-path-to-service-mesh/</guid>
      <description>原文链接：https://blog.aspenmesh.io/blog/2018/03/the-path-to-service-mesh/
作者：aspenmesh.io
译者：卢宇亮
 当我们谈论服务网格的时候，有几个问题经常被提及。这些问题的范围覆盖从简单的了解服务网格的历史，到产品和架构相关的比较深入的技术问题。
为了回答这些问题，通过 Aspen Mesh 之旅，我们带来三个主题的系列博文来讨论我们为什么选择了 Istio 。
作为开始，我将重点讨论我最经常被问到的问题之一：
为什么你选择服务网格，是什么原因促使你这样做？
LineRate ：高性能负载均衡软件 这个旅程起源于来自 Boulder 的初创公司 LineRate ，该公司在2013年被 F5 Networks 公司收购。 LineRate 除了是我曾经有幸参与的最聪明、最有才华的工程团队，还是一款轻量级高性能 L7 软件代理。当我说高性能时，我正在谈论的是如何将5年前在数据中心已经存在的服务器，变成一个高性能20+ Gbps 200,000+ HTTP 请求每秒的全功能负载。
虽然性能本身是引入注目的并为我们的客户打开了大门，但是我们的出发点在于客户期望付费的是容量，而不是硬件。这种见解是 LineRate 的核心价值主张。这个简单的概念将使我们的客户能够改变他们在应用之前使用和部署负载均衡的方式。
为了满足这个需求，我们交付了一种产品和商业模式，使我们的客户能够基于 COTS （可在市场上买到的）硬件按需多次复制他们的软件，从而不管部署多少实例都可以获得峰值性能。如果客户需要更多的容量，他们只需要简单的升级其订购层并部署更多的产品副本，直到达到他们许可证允许的带宽，请求速率或者交易速率。
这很有吸引力，我们也取得了一些成就，但是很快我们有了新的想法&amp;hellip;&amp;hellip;
效率优于性能 对于我们而言，应用架构正在发生变化，而客户的价值曲线随之变化的趋势也变得明显。我们在与资深团队沟通的过程中注意到，他们讨论的是诸如效率，敏捷，速度，印迹和横向扩展这类的概念。同时我们也开始听到这些领域的创新者开始采用Docker的新技术，以及它将如何改变应用和服务交付的方式。
我们与这些团队交流的越多，思考我们如何开发自己的内部应用程序，我们就越意识到转变正在发生。团队从根本上改变他们交付应用的方式，结果是我们的客户开始更少的关注原始性能而是更多地关心分布式代理。这些转变还有更多地收益，包含减少应用的故障域，增加部署的灵活性和赋予应用将负载和网络作为配置管理的能力。
与此同时容器和容器编排引擎也开始登上舞台，因此我们开始致力于通过一个新的控制面板以容器的方式交付 LineRate 的产品，并深入的思考人们未来会如何使用这些新技术来交付应用。
这些发生在2015的早期讨论促使我们思考未来应用交付将会如何&amp;hellip;&amp;hellip;
与时俱进的想法 随着我们对于未来应用交付方式的思考，我们开始关注云原声分布式应用领域中有关策略和网络服务的概念。尽管我们仍然有很多不同的优先级项目，改变应用蓝图，云原生应用和基于DevOps交付模式的想法始终在我们思想的最前端。
在这个领域将会有一个新的市场。
我们设计了许多项目，但由于种种原因未能成功。我们亲切的称这些项目为 v1.0 ，v1.5 和 v2.0 。每个项目都有一种解决分布式应用架构（微服务）挑战的独特技术。
我们尽最大可能去思考。下一个应用交付控制架构（ ADC ):一个完全与 API 驱动的控制面板和一个分离的数据面板。数据面板可能来自云你能够设想到的任意一种形式：靠近微服务的专用硬件，商用软件，或者云原生组件（就像服务网格）。这种无限可扩展的架构可以实现优雅的平衡，能够完美的工作于任意规模的任意组织的任意一种工作。很有野心吧？我们陷入了为客户提供所有东西的陷阱。
接下来，我们在“1.5”中完善了我们的方法，我们决定开发一种策略语言&amp;hellip;&amp;hellip; 关键是要定义开源的策略接口并将它无缝地连接到完成工作的数据路径。在一个真正开放的平台中，其中一些数据路径也是开源的。但是仍然有很多发展中的事情没有一步到位；事后看来，其中一些事情已经到来了&amp;hellip;&amp;hellip; 市场还没有到来，加上我们在开源方面也没有专业知识，于是我们在描述我们在做什么以及为什么时遇到了麻烦。
但是想法仍然在我们的脑海中燃烧，而我们也没有放弃&amp;hellip;&amp;hellip;
在 2.0 版本，我们设计了一个帮助希望开始容器之旅的 F5 的用户的计划。技术是新的，而市场也刚刚开始走向成熟，我们决定用户将会通过三步开启他们的微服务之旅。</description>
    </item>
    
    <item>
      <title>使用 Minikube-in-a-Container 和 Jenkins 构建 Istio</title>
      <link>https://servicemesher.github.io/blog/building-istio-with-minikube-in-a-container-and-jenkins/</link>
      <pubDate>Mon, 04 Jun 2018 11:33:16 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/building-istio-with-minikube-in-a-container-and-jenkins/</guid>
      <description>原文链接：https://blog.aspenmesh.io/blog/2018/01/building-istio-with-minikube-in-a-container-and-jenkins/
作者：Andrew Jenkins
译者：戴佳顺
 AspenMesh提供一种Istio的分布式架构支持，这意味着即使与上游Istio项目无关，我们也需要能够测试和修复Bug。为此我们已开发构建了我们自己的打包和测试基础架构方案。如果你对Istio的CI（持续集成）也感兴趣，请参考我们已经投入使用，可能有用但还没有提交给Circle CI或GKE的组件。
这篇文章描述的是我们如何制作一个新的Minikube-in-a-Container容器和使用Jenkins Pipeline来构建和测试Istio的流程脚本。如果你觉得有必要，你可以通过docker run上运行minikube容器，然后在容器中部署功能性的kubernetes集群，不需要使用时可随时删除。Jenkins bits现在可帮助你构建Istio，也可以作为初始环境，以便在容器内构建容器。
Minikube-in-a-container 这部分描述了我们如何构建一个可以在构建过程中用来运行Istio冒烟测试的Minikube-in-a-container镜像。我们最初不是这么想的，我们最初使用本地localkube环境。我们不能让它在特定环境外工作，我们认为这是由于localkube和minikube之间有一点差异导致的。所以这是一个作为我们修复它使它能正常工作的记录。我们还添加了一些额外选项和工具，以便在生成的容器中使用Istio。这没有什么太多花样，但如果你要做类似的事情，我们希望它给你启发。
Minikube可能对你来说是一个可以在随身携带的笔记本上通过虚机运行自己kubernetes集群的非常熟悉的项目。这种方法非常方便，但在某些情况下（比如不提供嵌套虚拟化的云提供商），你就不能或者不希望基于虚机来完成了。由于docker现在可以运行在docker内部，我们决定尝试在docker容器内制作我们自己的kubernetes集群。一个非持久性的kubernetes容器很容易启动，也可进行一些测试，并在完成后进行删除。同时这也非常适合持续集成。
在我们的模型方案中，Kubernetes集群创建子docker容器（而不是Jérôme Petazzoni所提到的兄弟容器方案）。我们是故意这样做的，宁愿隔离子容器，而不是共享Docker构建的缓存。但是你应该在将你应用改造为DinD（docker in docker）之前阅读Jérôme的文章，也许DooD（在docker out of docker）是对你而言更好的方案。这篇文章供你参考。我们避免架构“变得更坏”的同时，对看起来“坏”和“丑”部分也应进行避免。
当你启动docker容器时，会要求docker在OS内核中创建和设置一些命名空间（namespaces），然后在通过这些命名空间启动你的容器。命名空间像一个沙箱：当你在命名空间中（即通过命名空间隔离），通常只能看到命名空间内的东西。chroot命令，不仅影响文件系统，还影响PID，网络接口等。如果你通过 --privileged 参数启动了一个docker容器，那么所涉及的命名空间隔离将获得额外的权限，比如创建更多子命名空间隔离的能力。这是完成docker-in-docker（即在docker中运行docker）的核心技巧。有关更多细节，Jérôme是这方面的专家，请在这里关注他的详细说明。
总之，这就是大致步骤：
 构建一个容器环境，完成docker，minikube，kubectl和依赖项的安装。
 添加一个假的systemctl shim来欺骗Minikube在没有真正安装systemd的环境中运行。
 使用 --privileged 参数启动容器
 让容器启动它自己内部的dockerd，这就是DinD的一部分。
 让容器通过参数 minikube --vm-driver = none 启动minikube，以便在容器中的minikube可以与与之一起运行的dockerd连接。
  所有你需要做的就是通过 docker run --privileged 运行容器，接着你就可以去使用kubectl了。这时如果你愿意，你可以在容器内运行kubectl，并得到一个真正的用完可随时删除的环境。
你现在可以试试它：
docker run --privileged --rm -it quay.io/aspenmesh/minikube-dind docker exec -it &amp;lt;container&amp;gt; /bin/bash # kubectl get nodes &amp;lt;....&amp;gt; # kubectl create -f https://k8s.</description>
    </item>
    
    <item>
      <title>Istio 0.8 发布了！</title>
      <link>https://servicemesher.github.io/blog/istio-0.8-release-note/</link>
      <pubDate>Fri, 01 Jun 2018 11:41:00 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/istio-0.8-release-note/</guid>
      <description>原文地址：Isito 0.8
译者：Jimmy Song
 北京时间 2018 年 6 月 1 日（儿童节）上午 9: 30 Istio 0.8.0 LTS（长期支持版本）发布。该版本除了常见的一堆错误修复和性能改进之外，还包含以下更新和新功能。
网络  改进了流量管理模型。我们终于准备好了推出新的流量管理配置模型。该模型增加了许多新功能并解决了先前模型的可用性问题。istioctl 中内置了一个转换工具来帮助您迁移旧模型。试用新的流量管理模型。 Ingress/Egress 网关。我们不再支持将 Kubernetes Ingress 配置与 Istio 路由规则相结合，因为这会导致一些错误和可靠性问题。Istio 现在支持独立于 Kubernetes 和 Cloud Foundry 平台的 ingress/egress 网关，并与路由规则无缝集成。 新的网关支持基于服务器名称指示（Server Name Indication）的路由，以及根据 SNI 值提供证书。HTTPS 访问外部服务将基于 SNI自动配置。 Envoy v2。用户可以选择使用 Envoy 的 v2 API 注入 sidecar。在这种模式下，Pilot使用 Envoy 的 v2 聚合发现服务 API将配置推送到数据平面。该方式提高了控制平面的可扩展性。 受限入站端口。我们现在将 Pod 中的入站端口限制为由该 Pod 内运行的应用程序所声明的端口。  安全  介绍 Citadel。我们终于给安全组件确定了名字。它就是我们之前称呼的 Istio-Auth 或 Istio-CA，现在我们将它称之为 Citadel。 多集群支持。对于多集群部署，支持在每集群中使用 Citadel，以便所有 Citade 都拥有相同的根证书且工作负载可以通过网格彼此验证。 验证策略。我们引入了可用于配置服务间认证策略身份认证（相互 TLS）和最终用户认证。这是启用相互 TLS 的推荐方式（通过现有的配置标志和服务注释）。了解更多。  遥测  自我报告。现在 Mixer 和 Pilot 产生的流量也会通过 Isitio 的遥测管道，就像网格中的其他服务一样。  部署  上碟 Istio 小菜。Istio 有丰富的功能，但是用户不一定要全部安装和使用。通过使用 Helm 或 istioctl gen-deploy，用户可以选择安装他们想要的功能。例如，用户可能只想安装 Pilot 并享受流量管理功能，无需处理 Mixer 或 Citadel。详细了解通过 Helm 定制和 istioctl gen-deploy。  Mixer 适配器  CloudWatch。Mixer 现在可以向 AWS CloudWatch 报告指标。了解更多。  0.</description>
    </item>
    
    <item>
      <title>Istio 的 GitOps——像代码一样管理 Istio 配置</title>
      <link>https://servicemesher.github.io/blog/gitops-for-istio-manage-istio-config-like-code/</link>
      <pubDate>Thu, 31 May 2018 21:12:03 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/gitops-for-istio-manage-istio-config-like-code/</guid>
      <description>译者：Jimmy Song
原文地址：GitOps for Istio - Manage Istio Config like Code
 在今年的哥本哈根 Kubecon 大会上，Weaveworks 的 CEO Alexis Richardson 与 Varun Talwar（来自一家隐形创业公司）谈到了 GitOps 工作流程和 Istio。会后 Weaveworks 的 Stefan Prodan 进行了的演示，介绍如何使用 GitOps 上线和管理 Istio 的金丝雀部署。
会谈和演示中解释了：
 什么是 GitOps？为什么需要它？ Istio 和 GitOps 的最佳实践是如何管理在其上运行的应用程序的。 如何使用 GitOps 工作流程和 Istio 进行金丝雀部署。  什么是GitOps？ GitOps 是实现持续交付的一种方式。“GitOps 使用 Git 作为声明式基础架构和应用程序的真实来源” Alexis Richardson 说。
当对 Git 进行更改时，自动化交付管道会上线对基础架构的更改。但是这个想法还可以更进一步——使用工具来比较实际的生产状态和源代码控制中描述的状态，然后告诉你什么时候集群的状态跟描述的不符。
Git 启用声明式工具 通过使用 Git 这样的声明式工具可以对整套配置文件做版本控制。通过将 Git 作为唯一的配置来源，可以很方便的复制整套基础架构，从而将系统的平均恢复时间从几小时缩短到几分钟。
GitOps 赋能开发人员拥抱运维 Weave Cloud 的 GitOps 核心机制在于 CI/CD 工具，其关键是支持 Git 集群同步的持续部署（CD）和发布管理。Weave Cloud 部署专为版本控制系统和声明式应用程序堆栈而设计。以往开发人员都是使用 Git 管理代码和提交 PR（Pull Request），现在他们也可以使用 Git 来加速和简化 Kubernetes 和 Istio 等其他声明式技术的运维工作。</description>
    </item>
    
    <item>
      <title>一个商用级Service Mesh服务的设计之道</title>
      <link>https://servicemesher.github.io/blog/the-desigin-patterns-for-a-commercial-service-mesh/</link>
      <pubDate>Wed, 30 May 2018 15:00:22 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/the-desigin-patterns-for-a-commercial-service-mesh/</guid>
      <description>作者介绍：田晓亮，8年软件行业经验，曾就职于三星，2012年进入云计算领域，对PaaS，DevOps，APM有深入的研究和实践经验，方案支撑近千台VM中的应用部署监控。 2016年加入华为担任架构师，负责微服务的Go语言开发框架及Service Mesh设计和落地。
原文地址：https://blog.csdn.net/karamos/article/details/80133231
图1 微服务架构需要解决的问题
微服务将原本内存中函数的调用转换为网络中的调用后，就牵扯到这些问题，而任何一个分支展开，都会涉及一系列的问题。业务开发者也许真的有精力去学习架构相关的复杂问题，然而对于公司来说，真正有价值的是业务本身，让业务开发者解决这些问题需要花费浪费大量的时间精力，导致业务上线受到影响。那我们来看看是否有便捷的方式来解决业务开发者的痛点。
Chassis模式 一句话来概括：一种语言开发框架来作为微服务开发的底座，封装掉复杂性，帮助你解决跨网络带来的问题，让用户聚焦在上层业务逻辑的开发。通常情况下会实现以下功能：
 日志、Metrics、分布式追踪数据上报 健康检查 对接统一的配置中心实现动态配置 对接注册中心 实现负载均衡、熔断降级、容错、限流等保证高可靠运行的功能  现在我们来看看业界有哪些可用的Chassis框架
 Spring Cloud ServiceComb Dubbo Go-Micro Go-Kit  先不细去纠结微服务的严格定义，也先暂且搁置诸如“某些老旧框架是否是真的微服务框架”这类争议，从实现方式来看，上述服务化框架都是将分布式系统开发的复杂性进行了一定程度的封装然后提供了简便的开发接口供使用者调用。但是，用这种方式构建微服务还有一些问题：
 多语言SDK支持：微服务提倡不同组件使用最适合它的语言开发，但是这需要每种语言都有开发框架，不断实现相同的功能。上面可以看到只有go语言和Java语言出现了微服务开发框架，其他语言呢？ 不论代码侵入程度，都需要开发者思考如何与SDK结合，并从代码层面做出改变，对于大部分开发者来说都是一个高曲线的学习过程。 绑定了特定技术栈，一旦想抽身就需要一定程度上的代码改造。 老旧单体应用由于无人维护，耦合程度高等问题无法进行改造，在进行微服务拆分的过程中重用遗留代码变得无比困难。而且微服务的拆分难以分步进行，需要一个相对较长的周期将系统整体拆分后才能上线。  我们知道技术演进来自于在实践中不断地将功能抽象，解耦，封装，服务化。
 云计算技术出现前是数据中心虚拟化，不断地实践使技术发展形成理论和新的实践。IaaS是一种封装，如今开发者与大部分技术团队不需要再学习虚拟化等技术以及如何维护数据中心。 没有TCP/IP的时代，开发人员需要自己考虑网络间数据包的传输，以及网络传输代码与业务代码完全耦合的问题，如今，开发者已经不需要关心，操作系统和开发语言已经封装好网络传输过程。 是否也可以把语言框架提供的能力抽象，成为服务？  在引入后面内容前，我先介绍下SideCar模式
SideCar模式  在近些年受到Kubernetes对容器调度方式的启示而日渐受到关注的一种功能部署模式，也是一种微服务的设计模式。 主要利用了一个Pod中的容器可以共享存储与网络的能力，或者说在一个Host中，这个模式也同样适用。 一般分为应用容器和工具容器，工具容器可以重用。  一个典型的场景如下: 图2 SideCar典型场景
应用容器与日志同步工具在同一个Pod下，共享存储卷，应用程序生成的日志文件会由日志同步工具收集并发送到类似kafka，elasticsearch这样服务中。
在这样的架构下我们获得了什么呢？
 以容器作为基础打包单元，那么就可以分给不同的团队进行开发测试 Sidecar容器可重用，可以与不同的容器结合 以容器作为错误边界，使服务能够独立开发和测试，比如应用服务在没有日志保存功能的情况下也可以独立运行 独立回滚与更新（但需要考虑复杂的版本组合，建议使用语义版本管理对版本进行控制）  在这个模式的基础之下，我们引入了Service mesh。
Service Mesh 新瓶中的那一杯老酒 什么是Service Mesh Service mesh最早是由Linkerd给出的定义，我们来看看英文版:
 A service mesh is a dedicated infrastructure layer for handling service-to-service communication.</description>
    </item>
    
    <item>
      <title>深入解读Service Mesh背后的技术细节</title>
      <link>https://servicemesher.github.io/blog/deepin-service-mesh-tech-details/</link>
      <pubDate>Wed, 23 May 2018 16:09:57 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/deepin-service-mesh-tech-details/</guid>
      <description>在Kubernetes称为容器编排的标准之后，Service Mesh开始火了起来，但是很多文章讲概念的多，讲技术细节的少，所以专门写一篇文章，来解析Service Mesh背后的技术细节。
原文地址：刘超的通俗云计算
一、Service Mesh是Kubernetes支撑微服务能力拼图的最后一块
在上一篇文章为什么 kubernetes 天然适合微服务中我们提到，Kubernetes是一个奇葩所在，他的组件复杂，概念复杂，在没有实施微服务之前，你可能会觉得为什么Kubernetes要设计的这么复杂，但是一旦你要实施微服务，你会发现Kubernetes中的所有概念，都是有用的。
在我们微服务设计的是个要点中，我们会发现Kubernetes都能够有相应的组件和概念，提供相应的支持。
其中最后的一块拼图就是服务发现，与熔断限流降级。
众所周知，Kubernetes的服务发现是通过Service来实现的，服务之间的转发是通过kube-proxy下发iptables规则来实现的，这个只能实现最基本的服务发现和转发能力，不能满足高并发应用下的高级的服务特性，比较SpringCloud和Dubbo有一定的差距，于是Service Mesh诞生了，他期望讲熔断，限流，降级等特性，从应用层，下沉到基础设施层去实现，从而使得Kubernetes和容器全面接管微服务。
二、以Istio为例讲述Service Mesh中的技术关键点
就如SDN一样，Service Mesh将服务请求的转发分为控制面和数据面，因而分析他，也是从数据面先分析转发的能力，然后再分析控制面如何下发命令。今天这篇文章重点讲述两个组件Envoy和Pilot
一切从Envoy开始
我们首先来看，如果没有融入Service Mesh，Envoy本身能够做什么事情呢？
Envoy是一个高性能的C++写的proxy转发器，那Envoy如何转发请求呢？需要定一些规则，然后按照这些规则进行转发。
规则可以是静态的，放在配置文件中的，启动的时候加载，要想重新加载，一般需要重新启动，但是Envoy支持热加载和热重启，一定程度上缓解了这个问题。
当然最好的方式是规则设置为动态的，放在统一的地方维护，这个统一的地方在Envoy眼中看来称为Discovery Service，过一段时间去这里拿一下配置，就修改了转发策略。
无论是静态的，还是动态的，在配置里面往往会配置四个东西。
一是listener，也即envoy既然是proxy，专门做转发，就得监听一个端口，接入请求，然后才能够根据策略转发，这个监听的端口称为listener
二是endpoint，是目标的ip地址和端口，这个是proxy最终将请求转发到的地方。
三是cluster，一个cluster是具有完全相同行为的多个endpoint，也即如果有三个容器在运行，就会有三个IP和端口，但是部署的是完全相同的三个服务，他们组成一个Cluster，从cluster到endpoint的过程称为负载均衡，可以轮询等。
四是route，有时候多个cluster具有类似的功能，但是是不同的版本号，可以通过route规则，选择将请求路由到某一个版本号，也即某一个cluster。
这四个的静态配置的例子如下：
如图所示，listener被配置为监听本地127.0.0.1的10000接口，route配置为某个url的前缀转发到哪个cluster，cluster里面配置负载均衡策略，hosts里面是所有的endpoint。
如果你想简单的将envoy使用起来，不用什么service mesh，一个进程，加上这个配置文件，就可以了，就能够转发请求了。
对于动态配置，也应该配置发现中心，也即Discovery Service，对于上述四种配置，各对应相应的DS，所以有LDS, RDS, CDS, EDS。
动态配置的例子如下：
控制面Pilot的工作模式
数据面envoy可以通过加装静态配置文件的方式运行，而动态信息，需要从Discovery Service去拿。
Discovery Service就是部署在控制面的，在istio中，是Pilot。
如图为Pilot的架构，最下面一层是envoy的API，就是提供Discovery Service的API，这个API的规则由envoy定，但是不是Pilot调用Envoy，而是Envoy去主动调用Pilot的这个API。
Pilot最上面一层称为Platform Adapter，这一层是干什么的呢？这一层不是Kubernetes, Mesos调用Pilot，而是Pilot通过调用Kubernetes来发现服务之间的关系。
这是理解Istio比较绕的一个点。也即pilot使用Kubernetes的Service，仅仅使用它的服务发现功能，而不使用它的转发功能，pilot通过在kubernetes里面注册一个controller来监听事件，从而获取Service和Kubernetes的Endpoint以及Pod的关系，但是在转发层面，就不会再使用kube-proxy根据service下发的iptables规则进行转发了，而是将这些映射关系转换成为pilot自己的转发模型，下发到envoy进行转发，envoy不会使用kube-proxy的那些iptables规则。这样就把控制面和数据面彻底分离开来，服务之间的相互关系是管理面的事情，不要和真正的转发绑定在一起，而是绕到pilot后方。
Pilot另外一个对外的接口是Rules API，这是给管理员的接口，管理员通过这个接口设定一些规则，这些规则往往是应用于Routes, Clusters, Endpoints的，而都有哪些Clusters和Endpoints，是由Platform Adapter这面通过服务发现得到的。
自动发现的这些Clusters和Endpoints，外加管理员设置的规则，形成了Pilot的数据模型，其实就是他自己定义的一系列数据结构，然后通过envoy API暴露出去，等待envoy去拉取这些规则。
常见的一种人工规则是Routes，通过服务发现，Pilot可以从Kubernetes那里知道Service B有两个版本，一般是两个Deployment，属于同一个Service，管理员通过调用Pilot的Rules API，来设置两个版本之间的Route规则，一个占99%的流量，一个占1%的流量，这两方面信息形成Pilot的数据结构模型，然后通过Envoy API下发，Envoy就会根据这个规则设置转发策略了。
另一个常用的场景就是负载均衡，Pilot通过Kubernetes的Service发现Service B包含一个Deployment，但是有三个副本，于是通过Envoy API下发规则，使得Envoy在这三个副本之间进行负载均衡，而非通过Kubernetes本身Service的负载均衡机制。
三、以Istio为例解析Service Mesh的技术细节
了解了Service Mesh的大概原理，接下来我们通过一个例子来解析其中的技术细节。
凡是试验过Istio的同学都应该尝试过下面这个BookInfo的例子，不很复杂，但是麻雀虽小五脏俱全。
在这个例子中，我们重点关注ProductPage这个服务，对Reviews服务的调用，这里涉及到路由策略和负载均衡。</description>
    </item>
    
    <item>
      <title>Istio Service Mesh 教程</title>
      <link>https://servicemesher.github.io/blog/istio-service-mesh-tutorial/</link>
      <pubDate>Tue, 22 May 2018 12:16:22 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/istio-service-mesh-tutorial/</guid>
      <description>本文是 Istio 管理 Java 微服务的案例教程，使用的所有工具和软件全部基于开源方案，替换了 redhat-developer-demos/istio-tutorial 中的 minishift 环境，使用 kubernetes-vagrant-centos-cluster 替代，沿用了原有的微服务示例，使用 Zipkin 做分布式追踪而不是 Jaeger。
本文中的代码和 YAML 文件见 https://github.com/rootsongjc/istio-tutorial。
原文地址：https://jimmysong.io/posts/istio-tutorial/
准备环境 在进行本教程前需要先准备以下工具和环境。
 8G 以上内存 Vagrant 2.0+ Virtualbox 5.0 + 提前下载 kubernetes1.9.1 的 release 压缩包 docker 1.12+ kubectl 1.9.1+ maven 3.5.2+ istioctl 0.7.1 git curl、gzip、tar kubetail siege  安装 Kubernetes 请参考 kubernetes-vagrant-centos-cluster 在本地启动拥有三个节点的 kubernetes 集群。
git clone https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster.git cd kubernetes-vagrant-centos-cluster vagrant up  安装 Istio 在 kubernetes-vagrant-centos-cluster 中的包含 Istio 0.7.1 的安装 YAML 文件，运行下面的命令安装 Istio。</description>
    </item>
    
    <item>
      <title>Service Mesh：重塑微服务市场</title>
      <link>https://servicemesher.github.io/blog/service-mesh-rebuild-microservice-market/</link>
      <pubDate>Mon, 21 May 2018 21:48:05 +0800</pubDate>
      
      <guid>https://servicemesher.github.io/blog/service-mesh-rebuild-microservice-market/</guid>
      <description>今天我们不谈技术，不谈架构，也不谈具体的产品，我们来聊一聊在未来一两年之内，Service Mesh技术会在微服务相关的市场带来什么样的变化？
原文地址：https://skyao.io/publication/service-mesh-rebuild-microservice-market
大家好，我是敖小剑，今天给大家带来的这个主题叫做 “Service Mesh：重塑微服务市场”。
刚才主持人张亮提到说，过去一年Service Mesh成为一个热词。基本上，在国内的话，我差不多是Service Mesh最早的布道师。可能如果大家之前有看相关的资料的话，应该会看到一些我的资料。我先后做过几场的演讲，做过一些技术的分享，也写过很多文章。但在此之前，这些内容可能更多的都是集中在技术领域。那今天我们会特殊一点，我们今天不谈详细的技术，不谈具体的架构，我们也不谈具体的产品。后面的这些名词，Istio/Conduit/Envoy/Linkerd/Nginmesh，这些词可能听过，可能没听过，但没问题，今天这些我们统统都不讲。我们今天要讲另外一个东西：我们会聊一聊在未来一两年之内，Service Mesh技术会在微服务相关的市场带来什么样的变化？
主要内容会是三大块：首先我们会看一下目前微服务的市场的一些现状，然后接下来我们会探讨一下它的商业模式，在第三块，我们会重点讲一下Service Mesh对PaaS的意义。
OK，第一块，微服务的现状。
我们快速过一下。
目前微服务的背景是这样，首先目前在市场上是有这么一个潮流：传统企业会慢慢向互联网技术转型，其中微服务和容器是这个技术转型的核心。这个市场比较大，大家也都看好这样一个方向，这是大的时代背景。
简单回顾一下，微服务在国内，基本上是在2015年开始兴起。2016/2017这两年在国内的基本上就是大热了。我们能看到的是，未来这一两年之内，这个热潮应该继续延续。主要还是因为微服务这个技术是用于解决实际问题的，另外它也同样适用于各种企业。这样的大背景之下，我们来看现在使用微服务的客户现状。
实际上，我们之前在谈到Service Mesh技术为什么演进的时候，我们有提到，在Service Mesh之前，第一代的侵入式微服务框架，它的门槛相对稍微高一点，典型的代表的是Dubbo，Spring Cloud。对于传统企业来说，传统企业其实缺乏一些互联网的技术基因，这些包括技术，人才，经验，还有开发流程。在实际的市场当中，我们可以看到，大多数企业，虽然他们试图在微服务方面有一些转变，但实际上，在落地的时候还是会遇到一些问题。目前第二代的Service Mesh技术其实主要是冲着解决这个问题来的。他的思路在于要想办法用Service Mesh这样一个技术来降低微服务落地的门槛，最后帮助传统企业完成整个技术转型。这是目前大的背景和现状，我们下面来详细聊一下在这个背景当中一些具体的东西。
微服务的一个痛点：落地很难。
在这个地方我放了一个冰山图，左边的有一个坐标，就是说要实现好一个微服务，技术要求大概是一个什么样子，我这边简单的画了一下。
实际上我们可以看到，就是说如果以60分为及格线的话，那很遗憾的是，虽然这个冰山我们看它的体积非常的巨大，这个市场规模是非常大的，但实际上到目前真正能够落地的，能够浮在水面上的，其实并不多。这个问题在哪里？
因为它落地太难了。
落地难的原因是门槛比较高。我们简单的罗列了一下，比如说典型的Spring Cloud，他的技术栈，我们看到的这些特性的列表。大家可以看到非常多的东西，左边这个地方Spring Cloud的各个组件。大家如果用过Spring Cloud的都会比较熟悉。当然两边并不是严格对称，这只是一个示意。
实际上在这样的一个巨大的特性列表和组件列表当中，比较头疼的是：如果你是一个新人的话，你要第一时间掌握的东西其实是非常多的。Hello Would都很简单，但是你真的要掌握，这些东西是要一个一个吃透的。
为什么这个门槛会这么高？在这里面要指出一点，就是说：解决问题的思路有点不太对。
我们先看左边这个图，我们现在如果是想要一辆汽车，那OK，可以像左边这个图一样。我们看到一辆汽车分解之后是会有多少个零件？我们现在通过类库的方式，实际去组装辆汽车，我可以给你不同的组件，不同的类库，然后告诉你这个是发动机，这个是轮胎，这个是刹车……这确实会比自己从头到尾，从每一个螺丝钉开始制造，去组装整车要轻松的多，比如说至少有个成熟的发动机，至少方向盘可以不用自己做了。但是实际上，对用户而言，必须要对整体有非常深的认识：你知道每个组件能做什么，选择合适的组件，并把他们并拢起来。这样对一个系统的了解是需要比较深的。
我们再看看右边：你组装出来的东西是什么样子？最上面这个跑车可能是所有人的梦想，对吧？但实际当中，不同的用户，他的能力是不一样的，他的投入也不一样。那他最终得到产出品，很有可能不是上面的这个让大家心动的跑车。很可能只是一个普通的大众，只能只一个QQ，甚至，其实最后一张图非常凄惨：不知道出来的会是什么，很可能是接近无法使用的产品。
在下一代的Service Mesh当中，会用其他的方式来完成这个事情。
首先通过智能代理的方式，屏蔽掉大家对底层各个组件的认知。Service Mesh会通过直接使用Sidecar的方式来完成这些功能。
从思路上说，在这个时候，最大的事情是调整战略。
我们回到需求：客户用这些东西的需求是什么？它的目标是把这个车造出来，但造出这个车的下一步，是开着它上路，去该去的地方。造车，并不是他的最终的目标，对吧？我们回到现实的例子，大家学习Spring Cloud的目标是仅仅掌握Spring Cloud吗？我们说到，做微服务的实现，是把我们体系架构在微服务之上，然后让整个体系可以更快更好的运转。所以呢，客户真正的需求是用微服务做开发，做应用开发，应用是它的核心价值。这种情况下，对于微服务系统本身的掌握，要求其实不应该那么高。
比如说我随便举个例子，我相信在座的各位，很多同学开过车对吧？你可能开车的驾驶技术很高，但是如果我们现在，举个例子说：我给你一堆组件给你组，你能不能组装成一辆车？我相信在坐的同学应该没有几个能办得到。
所以，在这个地方，在Service Mesh里面，最重要的是：我们会做一个思路的转变。我们不再以组件的方式给客户提供服务，而且直接给客户成品，而且是精心打磨的成品。这个大家梦想中的跑车，开箱即用，直接呈现在客户面前。它非常的方便，可以非常快速地使用它。他的品质是经过打磨好之后的，然后客户只需要知道该怎么驾驶就好了。
这是整个Mesh的思路。
在这个思路背后，代表了一个重要的核心理念。我们会看到，第一代的微服务将当时微服务开发的门槛降低了，在第一代微服务之前，你需要一切从零开始，你需要从每一行代码开始。换句话说，在你造整车的时候，你需要从每个螺丝钉开始，这必然是很难的。
第一代微服务至少提供了一些成熟的组件，比如说发动机OK啦，这个门槛它降低了一部分。第二代微服务，我们是希望在这个基础上，将门槛进一步降低。60分不再是及格线，我们希望将它降成30分。这个目标如果能够达成，对于期望用微服务来做技术革新的企业来说，他这个时候可以更容易地落地。大家可以想象，一场考试，及格线是60分和及格线是30分，这个时候及格率会发生质的变化，这个时候能释放出来的市场规模也会远远大于前者。
OK，这个第一阶段我们讲好。
嗯，在这个地方，我想问大家一个问题：在座的各位，有没有哪一位所在的企业是真正的将微服务落地在一线生产上的？张亮兄？OK，你这个没问题。还有没有哪一位？OK？好，这个属于冰山水面上的部分。后面还有没有其他同学？有没有同学做过尝试的？就是在你们的实际的生产当中，实际落地微服务的架构，OK，这边有些同学。
好，实际上调查的和我们预期的还是有点像的。真正的大家能够把微服务落地的，就是冰山上面露出来的一小部分。
OK，我们进行第二个探讨：Service Mesh和微服务市场模式的探讨。
我先抛出一个问题：假设现在有一个公司，他要推微服务，但它确实之前没有这样的经验，它可能也缺乏这样的人才，所以在技术能力上它会有些欠缺。那这个时候怎么办？
哪位同学能给我想一个办法？或者说如果现在你的领导和你说：我们要上微服务了，有什么办法？这个很现实的，领导明天就你定方案，然后你发现你的团队好像大家都没玩过，也都不会。请你告诉我怎么办？有没有哪个同学给我一个想法？
 注：现场互动，有同学回答说，需要领导重视。
 嗯，非常重视，我们明天就上！
 注：现场互动，有同学继续说，招人，外包。
 恩，招人和外包，还有别的吗？OK，好，这位同学至少已经找到了明天早上开始推行微服务的一些方案了。
OK，我们简单过一下，刚才这个同学这里有一个比较有意思的地方：招人。这个有个比较有意思的东西给大家轻松一下。
这个是我个人的玩笑，用于区分互联网企业的一个简单方式：当发现有些事情自己不会做，也没有合适的人手，没能力的时候怎么办？一般互联网公司的习惯都是：挖！没人是吧，看一下业界谁会，挖！挖不过来是吧，薪水乘2？OK，互联网公司一般习惯这么干。但是传统企业一般不喜欢这么干，这里还包括伪装成互联网，大家应该懂这个意思吧？嗯，他的业务有可能是互联网业务，但他的工作方式，整个运作可能是传统企业的方式。但它的业务模式可能是互联网产品。这种企业的通常情况下它的习惯是买！拿钱去买，但他能买到什么？
当然这是个玩笑，但是有时候还是挺准确的，大家可以私底下去验证一下。
那我们现在说说，能买什么？
在这个市场，能为微服务的开发提供什么样的产品，什么样的服务吗？刚才同学说了一个：外包。是的，这个很正常。确实有非常之多的外包，但还有两个，一个是咨询，教你怎么做；一个是培训，包括出书也是一种培训，现场培训是另一种。还有一种就是卖产品，微服务相关的各种产品。整个市场会提供这些产品，但我们会注意到：前三者是不一样的。咨询、培训、外包本质上是要提升客户的能力，就是让你的能力更强。如果大家记得前面的那条线的话，现在就是在你考试的时候，让你的考试能力更强。产品是帮你稍微降低一下门槛。比如我告诉你，第五道题的答案是B，你填上就好了。最终达到大家及格的目标，至少起码及格。
整个市场提供的产品，大概是这个样子。</description>
    </item>
    
  </channel>
</rss>